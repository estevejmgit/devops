**Formation devOps**
_La capsule - Batch Juin-AoÃ»t 2024_

:fire: Exercices et corrections formation devOps :fire:

---

**Semaine 5 - Containers et orchestration**

**Jour 3 : Kubernetes**

---

# 4 - SERVICE LOAD BALANCER

## 1 - SetUp

ðŸ‘‰ CrÃ©ez un manifeste "mywebserver-deployment.yml" dÃ©diÃ© Ã  un dÃ©ploiement de pods en suivant les 
contraintes suivantes :

- Le nom de lâ€™application dÃ©ployÃ©e sera "mywebserver"  
- Le nom du manifeste de dÃ©ploiement sera "mws-deployment"  
- Le conteneur dÃ©ployÃ© sera nommÃ© "nginx-hello", basÃ© sur lâ€™image nginxdemos/hello
dans sa derniÃ¨re version et devra exposer le port 80  
- 5 pods devront Ãªtre utilisÃ©s pour le dÃ©ploiement du conteneur "nginx-hello"  

```
apiVersion: apps/v1

kind: Deployment
metadata:
  name: mws-deployment
  labels:
    app: mywebserver
spec:
  replicas: 5
  selector:
    matchLabels:
      app: mywebserver
  template:
    metadata:
      labels:
        app: mywebserver
    spec:
      containers:
      - name: nginx-hello
        image: nginxdemos/hello:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 80
``` 

ðŸ‘‰ Appliquez le manifeste crÃ©Ã© prÃ©cÃ©demment afin de dÃ©ployer les pods contenant chacun un seul conteneur "nginx-hello".

```
kubectl apply -f mywebserver-deployment.yml
```

## 2 - Notion de service

Comme vu dans les challenges prÃ©cÃ©dents, la commande kubectl port-forward permet de binder un port dâ€™un conteneur sur la machine hÃ´te, ce qui est utile pour comprendre le fonctionnement de Kubernetes et s'entraÃ®ner, mais pas vraiment adaptÃ© dans un environnement de production.

En effet, la notion de service avec Kubernetes sera plus adaptÃ©e car elle permettra de rendre disponible une application web sur internet, mais Ã©galement de rediriger le trafic Ã©quitablement entre les pods afin de rÃ©partir la charge, câ€™est ce que lâ€™on appelle un load balancer.

ðŸ‘‰ CrÃ©ez un nouveau fichier nommÃ© "mywebserver-service.yml" et complÃ©tez le service ci-dessous afin de lâ€™adapter Ã  votre dÃ©ploiement prÃ©cÃ©demment crÃ©Ã©.

```
apiVersion: v1

kind: Service
metadata:
  name: mws-service
  labels:
    app: mywebserver

spec:
  type: LoadBalancer
  ports:
  - name: http
    port: 8080
    protocol: TCP
    targetPort: 80
  selector:
    app: mywebserver
  sessionAffinity: None
```

ðŸ‘‰ Trouvez lâ€™option Ã  appliquer Ã  la commande kubectl get afin de vÃ©rifier lâ€™Ã©tat des services.

```
kubectl get services
```

Lâ€™output de cette commande doit afficher une nouvelle ligne contenant "mws-service". Dans un environnement de production, la colonne "EXTERNAL-IP" affiche lâ€™IP publique permettant de joindre le service et donc lâ€™application dÃ©ployÃ©e via Kubernetes.

Fort heureusement, notre meilleur ami minikube permet de rediriger lâ€™hÃ´te local vers le service afin de simuler un contexte dans lequel lâ€™environnement de production (dÃ©ployÃ© via AWS, par exemple) expose une IP publique. Ã‡a peut paraÃ®tre compliquÃ©, mais rassurez-vous, Kubernetes se charge de tout !

ðŸ‘‰ Utilisez la commande suivante afin dâ€™obtenir une URL censÃ©e rediriger, via le service dÃ©ployÃ© prÃ©cÃ©demment, vers un pod exposant le port 80 du conteneur quâ€™il hÃ©berge.

```
minikube service mws-service --url
```
> http://192.x.x.2:31975

